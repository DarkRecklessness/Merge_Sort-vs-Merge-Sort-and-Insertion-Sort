#show raw.where(block: true): it => {
  set text(font: "Consolas")
  block(
    fill: gray.lighten(90%), 
    stroke: 1.0pt + gray,
    inset: 10pt

  )[#it]
}

//#set text(font: "Consolas")


#let _heading_builder(
    is_bold: true,
    is_smallcapsed: false,
    is_underlined: false,
    font_size: 16pt,
    vspace: 1em,
    body
) = {
    if is_smallcapsed {
        body = smallcaps(body)
    }

    if is_underlined {
        body = underline(body)
    }

    let body = text(
        size: font_size,
        weight: if is_bold { "bold" } else { "regular" },
        body
    )

    v(vspace, weak: true)
    align(center, body)
    v(vspace, weak: true)
}

#let conf(
    title: none,
    subtitle: none,
    author: none,
    year: none,
    outline_opts: none,
    body
) = {
    set text(lang: "ru", size: 11pt)
    set par(justify: true)

    pagebreak(weak: true)

    set page(
        footer: align(center, {
            line(length: 100%, stroke: 0.5pt)
            context counter(page).display("1")
        }),
    )

    // Headings style
    show heading.where(level: 1): h => _heading_builder(
        is_bold: true,
        font_size: 16pt,
        h.body
    )

    show heading.where(level: 2): h => _heading_builder(
        is_bold: false,
        is_smallcapsed: true,
        font_size: 14pt,
        h.body
    )

    show heading.where(level: 3): h => _heading_builder(
        is_bold: false,
        is_smallcapsed: true,
        is_underlined: true,
        font_size: 12pt,
        h.body
    )

    body
}

#set text(size: 14pt)


= Анализ MERGE+INSERTION SORT
\
Анализ проводился на трех типах тестовых данных: случайных, обратно отсортированных и почти отсортированных.

Для анализа были написаны 2 класс: *ArrayGenerator*, который отвечает за генерацию 3 разных групп массивов, *SortTester* класс для удобного тестирования, который замеряет время работы сортировки и записывает данные в файл для дальнейшего анализа.
\
*Реализации классов в файле main.cpp*.

- *ArrayGenerator*: 
  - Массивы, заполненные случайными целыми числами в диапазоне [0, 10000]. Для генерации использовался генератор std::mt19937 и распределение std::uniform_int_distribution для обеспечения равномерного распределения.
  - Обратно отсортированные данные: Массивы, элементы которых упорядочены по невозрастанию.
  - Почти отсортированные данные: Массивы, полученные из полностью отсортированных путем выполнения небольшого числа случайных обменов (в данной реализации 1% от размера массива).

- *SortTester*:
  - Сортировка каждого массива запускалась 5 раз и бралось среднее время выполнения, для того что бы минимизировать влияние внешних факторов.
  - Метод измерения времени: Использовалась библиотека std::chrono и high_resolution_clock для максимальной точности (мс).

Результаты замеров были сохранены csv файлы, по этим данным были простоены графики зависимости среднего времени выполнения сортировки в зависимости от размера массива.  
\

=== Графики

#figure(
  image("random.png", width: 100%),
  supplement: [График],
  caption: [
    Производительность на случайных данных.
  ],
)

#figure(
  image("reverse.png", width: 100%),
  supplement: [График],
  caption: [
    Производительность на обратно отсортированных данных.
  ],
)

#figure(
  image("almost_sorted.png", width: 100%),
  supplement: [График],
  caption: [
    Производительность на почти отсортированных данных.
  ],
)

\
*Анализ графиков*

- Все прямые слегка изгибаются вверх, что соответвтует асимптотике O(NlogN), заметно это становится на графике стандартной сортировки слиянием при рандомных данных. Сам изгиб плохо виден, так как logN растет крайне медленно, для того что бы увидеть изгиб более явно можно взять N = 5'000'000.

- Можно заметить разницу в скорости работы двух алгоритмов, гибридная реализация очевидно гораздо быстрее. Однако ключевое наблюдение заключается в том, что разница во времени работы будет расти с увеличением N. Так например при N = 20'000 разница составляет около 7-8мс, при N = 100'000 разница достигает около 17-18мс. Это объясняется тем, что время работы алгоритма можно описать как $T(n) = c * N * log(N)$, где c - константа зависящая от накладных расходов. При оптимизации с помощью сортировки вставками мы как раз оптимизируем накладные расходы при размере подмассива <= 15, тем самым можно описать время работы обычного мердж сорта как $T_1(n) = c_1 * N * log(N)$, гибридного как    $T_2(n) = c_2 * N * log(N)$. Рассмотрим их разницу $Delta T = (c_1 - c_2) * N * log(N)$, отсюда видно, что при увеличении N разница так же будет расти.

- Рассмотрим особый случай: На графике 3 видно, что константа $c_2$ для гибридного алгоритма ещё меньше, чем для остальных случаев. Это связано с тем, что на почти отсортированных массивах Insertion Sort работает за почти линейное время.


= Вывод 
Оптимизация алгоритма Merge Sort путем замены его на более простой алгоритм, с меньшей константой, при небольших значениях N, не меняет его асимптотическую сложность, но сушественно уменьшает константу накладных расходов. Это ведет к масштабируемому преимуществу - чем больше размер массива, тем более эффективен гибридный алгоритм Merge Sort + Insertion Sort. Этот алгоиритм так же более предпочитителен по сравнению со стандратным, так как в особых случаях (например, почти отсортированные массивы) он может показать более значительный прирост в производительности.

\
\
\

*Ссылки на код*:
- Посылка на Codeforces:

  https://dsahse25.contest.codeforces.com/group/SLdI1pWUpC/contest/647790/submission/348220090

- Ссылка на репозиторий:

  https://github.com/DarkRecklessness/Merge_Sort-vs-Merge-Sort-and-Insertion-Sort

